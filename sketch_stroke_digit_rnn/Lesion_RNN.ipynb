{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b20e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447d8c",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965b3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumFromOneHot(inp):\n",
    "    for i in range(10):\n",
    "        if inp[i] == 1:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69400a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stroke_sequence(sequence, save_path=None, show=True):\n",
    "    \"\"\"\n",
    "    sequence: numpy array or list of shape (T, 4) where each row is [dx, dy, eos, eod]\n",
    "    save_path: optional path to save the plot as an image\n",
    "    show: whether to display the plot\n",
    "    \"\"\"\n",
    "    x, y = 0, 0\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for dx, dy, eos, eod in sequence:\n",
    "        x += dx*28\n",
    "        y += dy*28\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if eos > 0.5:  # end of stroke\n",
    "            xs.append(None)\n",
    "            ys.append(None)\n",
    "\n",
    "        if eod > 0.5:\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.plot(xs, ys, linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f162670",
   "metadata": {},
   "source": [
    "# 1. Loading the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bb9a8",
   "metadata": {},
   "source": [
    "### 1.1 Define the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e6bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitToStrokeLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, num_layers=2, batch_size=32):\n",
    "        super(DigitToStrokeLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Linear(10, hidden_size)  # From one-hot to hidden dim\n",
    "        \n",
    "        # LSTM\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        # Inital hidden state is the one-hot of number\n",
    "        # Initial input is [0, 0, 0, 0, 0]\n",
    "        # Input at t > 0 is output from t-1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=4,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        self.output_head = nn.Linear(hidden_size, 4)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.sigmoid = nn.Sigmoid()  # For eos/eod\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None, onehot_digit=None):\n",
    "        \n",
    "        if onehot_digit != None and hidden == None:\n",
    "            # Embed the digit\n",
    "            h0 = self.embedding(onehot_digit)\n",
    "            h0 = h0.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "            c0 = torch.zeros_like(h0)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        elif hidden == None and onehot_digit == None:\n",
    "            hidden = (torch.zeros(self.num_layers, self.batch_size, self.hidden_size),\n",
    "                      torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "            \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.output_head(out)\n",
    "        \n",
    "        out[:, :, 0:2] = self.tanh(out[:, :, 0:2])\n",
    "        # out[:, :, 2:] = self.sigmoid(out[:, :, 2:])\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401329e5",
   "metadata": {},
   "source": [
    "### 1.2 Load the model from pre-saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c63c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitToStrokeLSTM(\n",
       "  (embedding): Linear(in_features=10, out_features=512, bias=True)\n",
       "  (lstm): LSTM(4, 512, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (output_head): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DigitToStrokeLSTM(hidden_size=512, num_layers=2).to(device)\n",
    "model.load_state_dict(torch.load('model_weights/sketch_model_weights2.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820f24a",
   "metadata": {},
   "source": [
    "### 1.3 Function to generate digit from the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ad9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw the number using the RNN\n",
    "\n",
    "def generate_text(number):\n",
    "    model.eval()\n",
    "    \n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[number] = 1\n",
    "    temp_onehot = torch.tensor(temp_onehot, dtype=torch.float32).to(device)\n",
    "    \n",
    "    initial_input = torch.tensor([0, 0, 0, 0], dtype=torch.float32).to(device).unsqueeze(0).unsqueeze(1)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    output, hidden = model(initial_input, onehot_digit=temp_onehot)\n",
    "    output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "\n",
    "    outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "\n",
    "    for i in range(62-1):\n",
    "        output, hidden = model(output, hidden=hidden)\n",
    "        output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "        outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "        \n",
    "        # print(outputs[-1])\n",
    "        if output[:, -1, 3] == 1:\n",
    "            # print(\"HI\")\n",
    "            break\n",
    "    \n",
    "    draw_stroke_sequence(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30178f42",
   "metadata": {},
   "source": [
    "### 1.4 Test the drawing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the loaded model works\n",
    "generate_text(8) # <----- Change number and see it print it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5455727",
   "metadata": {},
   "source": [
    "# 2. Lesion the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAMAGE WEIGHTS\n",
    "\n",
    "def damage_smallest(model, p_smallest): # energy constraint\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_smallest == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            weight_magnitudes = tensor.abs().view(-1)\n",
    "            k = int(weight_magnitudes.numel() * p_smallest)\n",
    "\n",
    "            if k == 0:\n",
    "                continue\n",
    "            threshold = weight_magnitudes.kthvalue(k).values.item()\n",
    "\n",
    "            mask = tensor.abs() >= threshold\n",
    "            param.data.mul_(mask)\n",
    "\n",
    "def damage_fas(model,  p_block, p_reflect, p_filter):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_block + p_reflect + p_filter == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            flat_weights = tensor.view(-1)\n",
    "            nonzero_indices = (flat_weights!=0).nonzero(as_tuple=True)[0]\n",
    "            num_nonzero_indices = nonzero_indices.numel()\n",
    "            if num_nonzero_indices == 0:\n",
    "                continue\n",
    "\n",
    "            # percentage of weights damaged will be taken from the number of nonzero weights\n",
    "            # simulated fas damage occurs after energy constraint blockage\n",
    "            num_block = int(num_nonzero_indices * p_block)\n",
    "            num_reflect = int(num_nonzero_indices * p_reflect)\n",
    "            num_filter = int(num_nonzero_indices * p_filter)\n",
    "\n",
    "            shuffled_indices = nonzero_indices[torch.randperm(num_nonzero_indices, device=flat_weights.device)]\n",
    "\n",
    "            indices_block = shuffled_indices[:num_block]\n",
    "            indices_reflect = shuffled_indices[num_block:num_block+num_reflect]\n",
    "            indices_filter = shuffled_indices[num_block+num_reflect:num_block+num_reflect+num_filter]\n",
    "\n",
    "            # do damage\n",
    "            # blockage: set weights to 0\n",
    "            if p_block != 0:\n",
    "                flat_weights[indices_block] = 0\n",
    "\n",
    "            # reflect: halve weights\n",
    "            if p_reflect != 0:\n",
    "                flat_weights[indices_reflect] *= 0.5\n",
    "\n",
    "            # filter: low pass filter (lusch et al)\n",
    "            if p_filter != 0:\n",
    "                weights_to_filter = flat_weights[indices_filter]            # get weights before transformation\n",
    "                signs = torch.sign(weights_to_filter)                       # get signs of weights\n",
    "                abs_weights_to_filter = weights_to_filter.abs()             # get high_weight, should be in the 95th percentile for all weights\n",
    "                high_weight = torch.quantile(flat_weights.abs(), 0.95)      # scale weights to mostly between -1 and 1\n",
    "                x = abs_weights_to_filter / high_weight\n",
    "                transformed_weights = -0.2744 * x**2 + 0.9094 * x - 0.0192\n",
    "                gaussian_noise = torch.randn_like(transformed_weights) * 0.05\n",
    "                transformed_weights += gaussian_noise\n",
    "                transformed_weights = transformed_weights * signs * high_weight # rescale\n",
    "                flat_weights[indices_filter] = transformed_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = DigitToStrokeLSTM(hidden_size=512, num_layers=2).to(device)\n",
    "model1.load_state_dict(torch.load('model_weights/sketch_model_weights2.pth', map_location=device))\n",
    "model1.eval()\n",
    "\n",
    "damage_smallest(model, 0.69)\n",
    "damage_fas(model, 0.3, 0.45, 0.2)\n",
    "\n",
    "generate_text(8)\n",
    "\n",
    "\n",
    "model2 = DigitToStrokeLSTM(hidden_size=512, num_layers=2).to(device)\n",
    "model2.load_state_dict(torch.load('model_weights/sketch_model_weights2.pth', map_location=device))\n",
    "model2.eval()\n",
    "\n",
    "damage_smallest(model2, 0.69)\n",
    "damage_fas(model2, 0.3, 0.45, 0.2)\n",
    "\n",
    "generate_text(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
