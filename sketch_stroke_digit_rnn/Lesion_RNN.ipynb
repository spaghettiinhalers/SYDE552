{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b20e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447d8c",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965b3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumFromOneHot(inp):\n",
    "    for i in range(10):\n",
    "        if inp[i] == 1:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69400a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stroke_sequence(sequence, save_path=None, show=True):\n",
    "    \"\"\"\n",
    "    sequence: numpy array or list of shape (T, 4) where each row is [dx, dy, eos, eod]\n",
    "    save_path: optional path to save the plot as an image\n",
    "    show: whether to display the plot\n",
    "    \"\"\"\n",
    "    x, y = 0, 0\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for dx, dy, eos, eod in sequence:\n",
    "        x += dx*28\n",
    "        y += dy*28\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if eos > 0.5:  # end of stroke\n",
    "            xs.append(None)\n",
    "            ys.append(None)\n",
    "\n",
    "        if eod > 0.5:\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.plot(xs, ys, linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f162670",
   "metadata": {},
   "source": [
    "# 1. Loading the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bb9a8",
   "metadata": {},
   "source": [
    "### 1.1 Define the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28e6bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitToStrokeLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, num_layers=2, batch_size=32):\n",
    "        super(DigitToStrokeLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Linear(10, hidden_size)  # From one-hot to hidden dim\n",
    "        \n",
    "        # LSTM\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        # Inital hidden state is the one-hot of number\n",
    "        # Initial input is [0, 0, 0, 0, 0]\n",
    "        # Input at t > 0 is output from t-1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=4,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        self.output_head = nn.Linear(hidden_size, 4)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.sigmoid = nn.Sigmoid()  # For eos/eod\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None, onehot_digit=None):\n",
    "        \n",
    "        if onehot_digit != None and hidden == None:\n",
    "            # Embed the digit\n",
    "            h0 = self.embedding(onehot_digit)\n",
    "            h0 = h0.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "            c0 = torch.zeros_like(h0)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        elif hidden == None and onehot_digit == None:\n",
    "            hidden = (torch.zeros(self.num_layers, self.batch_size, self.hidden_size),\n",
    "                      torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "            \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.output_head(out)\n",
    "        \n",
    "        out[:, :, 0:2] = self.tanh(out[:, :, 0:2])\n",
    "        # out[:, :, 2:] = self.sigmoid(out[:, :, 2:])\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401329e5",
   "metadata": {},
   "source": [
    "### 1.2 Load the model from pre-saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2c63c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitToStrokeLSTM(\n",
       "  (embedding): Linear(in_features=10, out_features=512, bias=True)\n",
       "  (lstm): LSTM(4, 512, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (output_head): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model = DigitToStrokeLSTM(hidden_size = 512, num_layers=2).to(device)\n",
    "model.load_state_dict(torch.load('model_weights/sketch_model_weights2.pth', weights_only=True))\n",
    "model.eval()  # set to evaluation mode if you're doing inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820f24a",
   "metadata": {},
   "source": [
    "### 1.3 Function to generate digit from the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw the number using the RNN\n",
    "\n",
    "def generate_text(number):\n",
    "    model.eval()\n",
    "    \n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[number] = 1\n",
    "    temp_onehot = torch.tensor(temp_onehot, dtype=torch.float32).to(device)\n",
    "    \n",
    "    initial_input = torch.tensor([0, 0, 0, 0], dtype=torch.float32).to(device).unsqueeze(0).unsqueeze(1)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    output, hidden = model(initial_input, onehot_digit=temp_onehot)\n",
    "    output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "\n",
    "    outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "\n",
    "    for i in range(62-1):\n",
    "        output, hidden = model(output, hidden=hidden)\n",
    "        output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "        outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "        \n",
    "        # print(outputs[-1])\n",
    "        if output[:, -1, 3] == 1:\n",
    "            # print(\"HI\")\n",
    "            break\n",
    "    \n",
    "    draw_stroke_sequence(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30178f42",
   "metadata": {},
   "source": [
    "### 1.4 Test the drawing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAACuCAYAAABAzl3QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYMUlEQVR4nO2deVxc5bnHf2cWGCbMMOzDTljCFolJiATNvhhjTLSNqda91uXq1dRba1utW23V3t5qrbW12iZ1SapWW23MYjYTTVJICNnDvg0MYSDAAAPMPuf+cYYzQwDDMmej7/fz4ZM5MMN5IV/eeZfnfR6KpmkaBIIEkQndAAJhohB5CZKFyEuQLERegmQh8hIkC5GXIFmIvATJQuQlSBYiL0GyEHkJkoXIS5AsRF6CZCHyEiQLkZcgWRRCN4AgfuwuNy5a7Gi32NHea0e/3YW4MBUSw9WI06mglAvTBxJ5CSw9A04crG7HkdoOXOi2od1iQ7vFju4B56ivkcso6LUqpEap8Z2CJKybFQ+KonhpL0WC0f+zaeocwN6KNuwrb0NpYxdcnsnpcF2eHi9+ayYiQ4MD1MLRIfL+h+Hx0Dhl7Ma+8jbsq2hDdVvfqM8NUsgQown2fqgQo2Ueq4MUaO2xwmi2otk8gOYuK3qsvt45KjQYm+8pQH6ijtOfhcg7xaFpGs1dVpTUd6K4vhOHajrQ0Wcf8bnJEWqszI3F8pwY5MWFQRuiGPMQYOfZVvzs07Mwe4cYMxO02P7owoD9HCNB5J2CtHRbUVzXieK6TpTUd6Kl2zri8ygKmJ2kw4rcWKzMiUVGTOikxqvtFhtufbsE9Rf7AQDFTy5DXFjIhL/f5SATtimAqcfG9Kx1TO/a1DUw6nNDlHIsyIzCypxYLM2OQbQmcGPTGI0K62bF47V9NQCALyvbcXthSsC+/6UQeSWKzenG9jOt2HrUgJNN3aM+L1ghw9yUcBSlRaIoPRL5iToEKbhb2lqeHeuTt4LIS/CjsaMfW48a8HGZccQlrCC5DLOTdShKj8T8tEjMTtYhWCHnrX158VqEq5UwDzhxpqWH03sReSWAy+3B/sp2bCkx4FBNx7CvZ+s1WJkbi6K0SMxJCYdKyZ+slyKTUVB4Ny2CON68IPKKmPZeGz4sbcYHx5rQ2mMb8rUguQxr8uNwx/wUzEnW8bYxMBZsDjcAQKUk8v5HQdM0ius7sbWkCbvPm4ZtGiRHqHF7YTI2FCQhYlqQQK38ZqxORt6QIG7fAYi8IsHc78A/ThjxwbEm1HmXmgaRUcCy7FjcMT8ZizKjIZOJp5e9FKfbw/7BqZXc6kXkFRCaplHaaMbfjhqw85wJDpdnyNejQoNx67wkfLcwGQk67tZLA0lXv4N9THreKUjPgJPtZWvah2/PFk6PwB3zU7AqT8/pshYXlDZ2sY9z47Wc3otzeQdnyn8vbUZLtxUuDw23h4bL44HLTcPloeHyvtW43MzXVEoZ1s9NxMZlmQgX6bhuvNA0jRNNZmw92oQdZ1phv6SX1amVuHlOIr5bmIz06FCBWjl5Suo72cfz0yI5vRdn8vZYndh61ICtJU2jbk+OhsPtwV+PNOKTMiMeWZqBu69OFXT5ZzK43B5sO30Bb39dj0qTZdjXr0qNwG2Fybhupl6yP6M/xXWMvAoZhYKUcE7vxZm8fXYXfrO7Cv6T5SCFDMFyGeRyCgoZBYVMBrmMgkJOQS6joPRe13f0web0wGJz4eVdlXiv2IAfX5eFtfnxop6s+ON0e/DpiRb84WAtDJ1Dt2u1KgXWz03EbVclIzNWI1ALA0+7xcZONvMTwzAtWKITtgRdCFbmxmJPeRuWZcXgrqtTsTAjakzymXpseHVvFT4uM4KmmUCTH3x4Cn851ICnrs9BUTq3b0eTwe5y45MyI948WAejeeg7zuxkHW4vTMEN+XFTope9lMFeF+B+yABwHFVWd7EPChmFlMhpE3p9RWsvXt5Via+rLw75/PLsGDx5fTYyYsTTa9mcbvz9eDPePFg3bENhQUYUHl2WgUIe/kOF5M5NR9kdwK33FeKajChO7yeJkMhDNRfx4o6KIWNGuYzCLfOS8D8rZgQ0Mmq8WB1u/O1YE976qg7tlqFxsotnRGPj8gzMTYkQqHX8UdvehxWvfgWA2Ug58KMlkHM8xJOEvADg9tD45wkjXtlTDVOvr2ebFiTH/YvSUJQWicQINfRaFWe/NLeHRkNHPypNvaho7UVFqwUnm8xsAPYgK3Ji8OiyTMxK0sHqcKOkvhOljV1Iiw7FzXMTOWmb0Dz7r3N4r9gAAHh6TQ7uW5jG+T0lI+8gVocbmw7X482Ddej37qH7o5BRiNOpkKhTIyE8BInhIUgMV3v/DYFeq2IDRwDmWIzLQ8ND0+wyntu7fNfYOeCVlPmoarPA5vQMu+cg1+Xp8ciyDMxMCGM/19w1gIW/PgCAGT5sua8wgL8NcWCxOTH/pf3od7gRopSj5KnlCAtRcn5fyW1ShATJ8ciyTNwyLxm/21+ND441w+23pOHyMMdemrtGXp6TUYBCLmMlnSwalQJLsmLw30vTka0fviifGB6CWG0w2nrtONlkhsvtGfLHMxX4pMzIdiTfmpPAi7iABOUdJFoTjF/edAW+vyANByrbYTRbYTQPwGi2oqV76IFAfzw0hm3DjgWKAlIjpyFbr0FOnNb7oUGCLuQbI7ooikJBagR2nGlFv8ONSpNlSM8sdRwuDzYfaWCv77k6lbd7S1beQaZHTcP0BdOHfb7X5kSL2TpEaqN5ABe6bXB5aChkFBN7KqMgp5h1Zv8PGUVBHxbMipoVq5nwumVBSjh2nGkFABxv7JpS8n5U2sS+yy3MjMIMHtetJS/vaGhVSmjjlMiJ43Z/fSwU+K02HDeYcc81w//YpIjV4cbrX9ay1z+6NovX+0+twZdIyYnTQO2NsDreaIbE5sij8s6/G3HRuzx4XZ4es5J0vN6fyMsDCu+5MgAw9drGHeshRnqsTvzpqzoAzCT48Wtn8N4GIi9P+G9UlBnMArYkMPz563p2Uvyt2YmCxGgQeXnCP8LqeKO05TWaB/DnQ/UAAKWcwmMrMgVpB5GXJ2Yn6zC48Xdc4j3vSzsr2Hjku4tSkRShFqQdRF6e0KiU7CZGpakXvbbR04aKmX/XdWDnWRMAICo0CBsF6nUBIi+vFKQyQweaxjdmuRErLrcHL3xezl4/sSoLWhU/u2kjQeTlkYJUv/Vev7NeUuGDY01sZN8VCWHYMDdJ0PYQeXlEypO2rn4HXtlbzV4/vy5X8FMtRF4eideFID5MBQA42WweNf5CjLy8s4LNjXbTlfGiiFEm8vLMwsxoAIDN6cFr+6ov82xxUNrYhY/LjACYKLqn1uQI3CIGIi/PbFyRyebweq/YgEpTr8At+macbg+e/vQce/3EqizEaFQCtsgHkZdnEnQheGRpBgDmZMaz/zov6liHzYcbUNXGTNLyE8M4zbc7Xoi8AnDfwjSkRDIL+8caurDt9AWBWzQyLd1WNlE0RQG/vGkm5+fSxgORVwBUSjmeX5vHXr+4owJ9dpeALRqZ57edZzM+3jU/hfPqPuOFyCsQS7NjsCInFgDQbrHj9f01ArdoKPvK27C3vA0Ac2rl8VX8xuqOBSKvgDx7Qy6bSG/z4QbUtg9PByUEAw4Xntt2nr1+ek2OoDtpo0HkFZDkSDUeWpwOgDk4+sxn4pi8vb6/lo05XpARhXWz4gVu0cgQeQXmoSXpSIpgcu8W13cKPnmrbrPgL95wxyC5DC/cmCeqkgH+EHkFZqTJm0WgiDOapvHMZ+fYzOb/tSQdaSJOt0rkFQHLc2KHTN5+u1eYydvu8yYcbWAChlIi1Xh4Sbog7RgrRF6R8NzaXHbn7d3iRpRf4Hfnze5y46Wdlez1z67PEX0mSyKvSEiKUA/ZeXvmX+fgCUBGn7HyzpFGtuzr1emRWJkby9u9JwqRV0TcvygNaVFMOtgygxmfnDDyct+OPjve8OZfoCjg6TW5op2k+UPkFRHBCjleuHEme/2rXZW8HJN/dW81LN4dvlsKkjgvhBIoiLwiY0FmFNbkxwFgAsDv/MtRdPTZL/OqiWM0D+Cj0mYAQGiwAo/znPVmMhB5RcjP1+Vhunf4UN/Rj7s2HeMscH3T4QY2W+a9C6YLmqh7vBB5RUhUaDDe//5V7KmL8tZe3PtOKQYcgQ3eMfc78OExptdVKWW8ZngMBERekZIYrsb79xUi0luHrsxgxoPvl8HuGp5Qe6JsKTGwUWO3iLiW8WgQeUVMenQo3r33KmhUTDLPQzUdeOzDU3C5x59f+FJsTjfe+XcjACbXGB9p+AMNkVfkzEwIw1/vmYcQ74bBrnOmIRFfE+Wzky3o9NYJXpMfL1jWm8lA5JUABakReOvOuVDKmbXXrUebUN02ufDJL86b2MffHyE5txQg8kqERTOi8eNV2ez1YOTXRLA63GzBP71WhVmJ0szUTuSVEN8tTGbHv5+dvID2XttlXjEyxfUdbKK8pdnRkthNGwkir4QIDVawp3cdbg/eLW6c0Pc5UOmrKLokKyYQTRMEIq/EuOfqVHbsu6WkCf3jPLhJ0zQOVLUDYHLrcl1ilUuIvBJDH6bCulkJAJjU+h8fbx7X69t67WxB74KUCIRyXJmdS4i8EuT+Rb7VgU1HGsYVOtnZ74uTSI2aWEFzsUDklSDZei2KvBXkm7usuNAz9sizHr86yTq1+E4Ejwcir0TJ0vsKmLSNY9Wh2y/AR8dTmVWuIPJKlFitL9mdqWfsIZPdpOclCI0+zBe6OJ6e1z+0kq8C11xB5JUo/j3veOQdXGYDgAFH4CLUhIDIK1GGDBvGIW9atG+Foe5iX0DbxDdEXokSFeobNgzW/x0L6X5JRGrbibwEAfBPyhczjqM7ieFqNrlf3cX+gLeLT4i8EqWk3lcKa753zXcsyGUUe7ze0NkPZwAC24WCyCtRBkMaAaAofezyAr6hg9NNo8okjrSqE4HIK0EcLg+OG5ieNy5MheRxnoKY7yf79jOtAW0bnxB5JcgZYzdsTubtfn5a5LjjcVfP1LO1JT4/fUEUOYEnApFXgvj3lkXjGO8OEhUajKu9vW9LtxUnm7sD1TReIfJKjLPGHrznDUIPUsiwOCt6Qt/HP9v5tlPirEZ0OYi8EsLl9uCn/zyDwQjIHyzPHLJZMR6uzdMjSM789+8428pmzZESRF4JsflIA8578/Zm6zV4YNHEcy2EhSixxNtrX7TY8cU502VeIT6IvBKhuWsAr3qrrlMU8PK3r4BSPrn/vjuLfNUs/3CgVnITNyKvBKBpGk99epZdYbi7KBWzk8Mn/X0XZEQh33vsvby1FwerLl7mFeKCyCsBtp2+gEM1HQCYdd0fBaigH0VReHhJBnv9hsR6XyKvyOmzu/Dijgr2+oUbZwb00OS1ubHIjGF23MoMZhxr6LrMK8QDkVfk/H5/Ddq9UWMrcmIDXitCJqPw8FJf1Z83DtQG9PtzCZFXxNS292HT4QYAzJruszfkcnKftfnxSAxnChkequkYEjchZoi8IoWmaTy/7byvoN/idCRHcpPJUSGXYePyTPb6pZ0VvFYimihEXpGy+7wJh2uZSVqCLoStUcwV6+ckItt7IvlsSw8+PyP+XTcirwixOtz4xXbfJO2ZG3IREsRtQT+5jMJT1+ew17/+ogo2p7jPuBF5RcibB31V1xdmRmFVHj8F/RbNiMaiGcyuW0u3Fe96M6eLFSKvyGjuGsBbXzO5dxUyCs+t5bfq+pOrszF4uzcO1MLszZ4uRoi8IuNXuyrZ3LnfuyYVGTH8Vl3PidNiw9xEAIDF5sLv9gtTxHssEHlFREl9J3acZWJ1o0KD8KjfCgCfPH5tFlsDY0uJQbRH5Im8IsHtofHzz8vZ6ydWZUGrEiajTaxWhQcXMxFrLg+Nl/x2+MQEkVckfFTajIpWJtxxZoIWN89NErQ9DyxKg94bK7y/sh2HasQXtEPkFQE9Vid+s6eKvX5ubR57xkwo1EEK/GS1LwDol9srAlL/LZAQeUXA7/fXoMs7q187Kx7zUiMEbhHDjbMS2EpBVW0WfDTOLOxcQ+QVmKbOAbYSpUopw09XZ3/zC3hEJqPwjF88xat7qtFr46aA90Qg8grMb/dVs/ELDyxMQ4IuROAWDaUgNQJr8uMAAJ39Dmw61CBwi3wQeQWkymTBZ6daAADhaiXun8SZNC75yapsKLxj8M2HG0SzcUHkFZBX9lRh8ODCw0syoBFoaexyJEeqsaGAWf2w2F14exLVNwMJkVcgTjaZsae8DQAQqw0echhSjDy6LIM9Kv/OkUZ09I09rSpXEHkFwn9pbOPyTKiU3EaNTZZ4XQhuK0wGAFidbrx5sE7gFhF5BeFIbQeO1DKnFZIj1PhOgbAbEmPl4SXpUCkZZbaUGGDqmVjt40BB5OUZmqbx692+XveHK2dMOv8CX8RoVbirKBUAYHd58MeDwp53k8ZvbQpxqKYDp72J7bJiNVjrlzNMCjy4KA3TvIHxn5QZx137OJAQeXnmvWID+3jj8kzBt4HHS2RoMG6czdQ+HnC42Sg4ISDy8ojRPIAvK5kVBr1WxdsJiUAzGO8LAJ8cNwrWDiIvj2w92sRmeLytMBkKiYx1L+XKJB2bqORYYxcaOoQpzCLN354EsTnd+KiUCWxRyCjcepU0VhhGgqIobCjw633LhAnYIfLyxM6zrWzk2HUz9YjRTCyvrli4aXYCO17/R1mLIPl9ibw84T9RG1xukjIxGhWWZsUAYCpwChGsTuTlgbPGHpzyLo9l6zWYlzr59KRi4Oa5CezjI94EKXxC5OWBf5zwzcjvLErh9Sg7l1yZ5PsjFKIULJGXB2r8Sq2unhknYEsCS6w2GBpvutUaIu/UxNA5AADQqBQIV4sz7HEiUBSFjFhmycxotvK+20bk5Rin24ML3tRNKZHqKTNkGCTTLykK3/kdiLwcc6Hbym5MjLfMqhTIjNGwj2vaiLxTisEhAwAkTUV5Y309L9/jXiIvxzR1+eRNiZgmYEu4IVoTzD7u5Pl0BZGXY5r95J2Kw4bWbl9AehzPJ5+JvBwj8wt57OwX/txXoGk2+w2Lwom8U4qFmVHs473eA5dTiSYB31mIvBwzLzUCYSHM2u5XVRfhcIkr39dkae6yso/5npASeTlGKZdhqbdAtcXuwtEGaZSJGitG77AhSC6bcAX6iULk5YGVuXr28b4pNHSwOd3sUmBCeAjvR5qIvDywOCuaTdix+3wbBhzCHVoMJFtKDLB6KwYNFuDmEyIvD4QGK7DAO3Ez9drwxMdnJFWgeiT67C780Zt4hKKAh5ZwWyduJIi8PPHk6my24PWOs61440vp1Pgdib8ebvDlFM6PR7Zey3sbiLw8kRmrwWu3XMmWiXplbzW+OGcStlETpGfAySbbk8soPLZCmMIvRF4eWZEbiydW+VLl//Dvp1Bp6hWwRRPj7UN1sNiYcfv6OQlIi+a33NYgRF6eeWhxOtZ5s+QMONy4Z3MpjjV0CdyqsfPFuVb8+WsmwbRSTg0puM03RF6eoSgK/7s+H1ckMLNzU68Nt75djFf2VMEpsoIll/LBsSY8vPUEHN523l2UisRw4eI1KFrq016J0m6x4ZGtJ3Gs0dfrzkrS4bVbrsT0KHFFn9E0jT8cqMVv9lSzn1s/JxG/Wn+FoEkCibwC4vbQ+NNXdfjtXl9dCnWQHM+vzcOGgkRRnLrweGi8sL2cLfoCMDXamBrFwraPyCsCTjd347GPTg1Jm5QTp8X3rknFulnxgiWerm3vw//trsTu875dwSdXZ+PBxfyv6Y4EkVck9Ntd+MX2cnxYOjR1UuS0INw+PwV3zE/mJcsOTdM4bjDjra/qsa/CJ61cRuHlb18hqkTYRF6Rsb+iDa9/Wcvm8B1EKaewNj8eGwqSMDtZF/De2O2hsbfchLe+rsfJpqH31qoUePU7V2JFrriyWhJ5RcqJJjM2H27ArnOmYXnAlHIKefFhKEgJR0FqOOakhI+7V+63u1DVZkGVifk4WNWORr/zdgAQF6bCvddMx61XJYmyUhGRV+Rc6Lbi/RID/na0CT3W0atPJkeokRunxbRgBVRKGVRKOVRKGUKUcqiUcgQrZDD12lBl6kNVW++QONxLydZr8MCiNKydFS/qkgNEXokw4HBh11kTjjZ04rjBjPqLgc+Je01GJB5YlI5FmVGCrySMBSKvROnqd+CEwYzjBjNOGMw4beyGfYynNKYFyTFDr0FWrAZZeuYjW69FxLQgjlsdWIi8UwSHy4N2iw02pwc2pxt2lxtWB/PY5nLD6nBDpw5Ctl6DBF3IkIOhUoXIS5As4h2NEwiXgchLkCxEXoJkIfISJAuRlyBZiLwEyULkJUgWIi9BshB5CZKFyEuQLERegmQh8hIkC5GXIFmIvATJ8v9nFJvyHWCIvQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test if the loaded model works\n",
    "generate_text(8) # <----- Change number and see it print it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5455727",
   "metadata": {},
   "source": [
    "# 2. Lesion the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAMAGE WEIGHTS\n",
    "\n",
    "def damage_smallest(model, p_smallest): # energy constraint\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_smallest == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            weight_magnitudes = tensor.abs().view(-1)\n",
    "            k = int(weight_magnitudes.numel() * p_smallest)\n",
    "\n",
    "            if k == 0:\n",
    "                continue\n",
    "            threshold = weight_magnitudes.kthvalue(k).values.item()\n",
    "\n",
    "            mask = tensor.abs() >= threshold\n",
    "            param.data.mul_(mask)\n",
    "\n",
    "def damage_fas(model,  p_block, p_reflect, p_filter):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_block + p_reflect + p_filter == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            flat_weights = tensor.view(-1)\n",
    "            nonzero_indices = (flat_weights!=0).nonzero(as_tuple=True)[0]\n",
    "            num_nonzero_indices = nonzero_indices.numel()\n",
    "            if num_nonzero_indices == 0:\n",
    "                continue\n",
    "\n",
    "            # percentage of weights damaged will be taken from the number of nonzero weights\n",
    "            # simulated fas damage occurs after energy constraint blockage\n",
    "            num_block = int(num_nonzero_indices * p_block)\n",
    "            num_reflect = int(num_nonzero_indices * p_reflect)\n",
    "            num_filter = int(num_nonzero_indices * p_filter)\n",
    "\n",
    "            shuffled_indices = nonzero_indices[torch.randperm(num_nonzero_indices, device=flat_weights.device)]\n",
    "\n",
    "            indices_block = shuffled_indices[:num_block]\n",
    "            indices_reflect = shuffled_indices[num_block:num_block+num_reflect]\n",
    "            indices_filter = shuffled_indices[num_block+num_reflect:num_block+num_reflect+num_filter]\n",
    "\n",
    "            # do damage\n",
    "            # blockage: set weights to 0\n",
    "            if p_block != 0:\n",
    "                flat_weights[indices_block] = 0\n",
    "\n",
    "            # reflect: halve weights\n",
    "            if p_reflect != 0:\n",
    "                flat_weights[indices_reflect] *= 0.5\n",
    "\n",
    "            # filter: low pass filter (lusch et al)\n",
    "            if p_filter != 0:\n",
    "                weights_to_filter = flat_weights[indices_filter]            # get weights before transformation\n",
    "                signs = torch.sign(weights_to_filter)                       # get signs of weights\n",
    "                abs_weights_to_filter = weights_to_filter.abs()             # get high_weight, should be in the 95th percentile for all weights\n",
    "                high_weight = torch.quantile(flat_weights.abs(), 0.95)      # scale weights to mostly between -1 and 1\n",
    "                x = abs_weights_to_filter / high_weight\n",
    "                transformed_weights = -0.2744 * x**2 + 0.9094 * x - 0.0192\n",
    "                gaussian_noise = torch.randn_like(transformed_weights) * 0.05\n",
    "                transformed_weights += gaussian_noise\n",
    "                transformed_weights = transformed_weights * signs * high_weight # rescale\n",
    "                flat_weights[indices_filter] = transformed_weights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
