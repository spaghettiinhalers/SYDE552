{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b20e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447d8c",
   "metadata": {},
   "source": [
    "# Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e30563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for i in range(10000):\n",
    "    try:\n",
    "        data = np.loadtxt(f'../sequences/testimg-{i}-targetdata.txt', delimiter=' ')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File not found at path: {i}\")\n",
    "        continue\n",
    "    \n",
    "    inputOneshot = data[0, 0:10]\n",
    "    outputStrokes = data[:, 10:]\n",
    "    outputStrokes[:, 0] = outputStrokes[:, 0]/28\n",
    "    outputStrokes[:, 1] = outputStrokes[:, 1]/28\n",
    "    \n",
    "    \n",
    "    input_data.append(inputOneshot)\n",
    "    output_data.append(outputStrokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74adda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stroke_sequence(sequence, save_path=None, show=True):\n",
    "    \"\"\"\n",
    "    sequence: numpy array or list of shape (T, 4) where each row is [dx, dy, eos, eod]\n",
    "    save_path: optional path to save the plot as an image\n",
    "    show: whether to display the plot\n",
    "    \"\"\"\n",
    "    x, y = 0, 0\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for dx, dy, eos, eod in sequence:\n",
    "        x += dx*28\n",
    "        y += dy*28\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if eos > 0.5:  # end of stroke\n",
    "            xs.append(None)\n",
    "            ys.append(None)\n",
    "\n",
    "        if eod > 0.5:\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.plot(xs, ys, linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bc965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumFromOneHot(inp):\n",
    "    for i in range(10):\n",
    "        if inp[i] == 1:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84ec919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_stroke_sequence(output_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04766e4",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd2c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Finding the max length of a sequence\n",
    "max_length = 0\n",
    "j = 0\n",
    "for i in range(len(output_data)):\n",
    "    if len(output_data[i]) > max_length:\n",
    "        max_length = len(output_data[i])\n",
    "    j += 1\n",
    "\n",
    "print(max_length)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edeec1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "642bf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the sequences so that they are all the same size (good for batching)\n",
    "padded_output_data = np.zeros( (len(output_data), max_length, 4) )\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    padded_output_data[i, :len(output_data[i]), :] = output_data[i]\n",
    "    padded_output_data[i, len(output_data[i]):, :] = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37cfe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_data = np.zeros( (len(output_data), max_length, 4) )\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    padded_input_data[i, 0, :] = [0, 0, 0, 0]\n",
    "    padded_input_data[i, 1:, :] = padded_output_data[i, :max_length-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8523173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, onehot, inputs, outputstroke):\n",
    "        self.digit = onehot                     # shape: [N]\n",
    "        self.inputstroke = inputs               # list of [seq_len, 4] arrays\n",
    "        self.outputstroke = outputstroke        # list of [seq_len, 4] arrays\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.digit)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        digit = self.digit[idx]\n",
    "        inputs = self.inputstroke[idx]\n",
    "        outputs = self.outputstroke[idx]\n",
    "        return torch.tensor(digit, dtype=torch.float32), torch.tensor(inputs, dtype=torch.float32), torch.tensor(outputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1171d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokeDataset = StrokeDataset(input_data, padded_input_data, padded_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d67af144",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(strokeDataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8f994",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2082a2d",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "\n",
    "RNN:\n",
    "input_size = output_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e58d8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitToStrokeLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, num_layers=2, batch_size=32):\n",
    "        super(DigitToStrokeLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Linear(10, hidden_size)  # From one-hot to hidden dim\n",
    "        \n",
    "        # LSTM\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        # Inital hidden state is the one-hot of number\n",
    "        # Initial input is [0, 0, 0, 0, 0]\n",
    "        # Input at t > 0 is output from t-1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=4,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        self.output_head = nn.Linear(hidden_size, 4)\n",
    "        self.sigmoid = nn.Sigmoid()  # For eos/eod\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None, onehot_digit=None):\n",
    "        \n",
    "        if onehot_digit != None and hidden == None:\n",
    "            # Embed the digit\n",
    "            h0 = self.embedding(onehot_digit)\n",
    "            h0 = h0.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "            c0 = torch.zeros_like(h0)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        elif hidden == None and onehot_digit == None:\n",
    "            hidden = (torch.zeros(self.num_layers, self.batch_size, self.hidden_size),\n",
    "                      torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "            \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        out = self.output_head(out)\n",
    "        \n",
    "        out[:, :, 0:2] = self.tanh(out[:, :, 0:2])\n",
    "        # out[:, :, 2:] = self.sigmoid(out[:, :, 2:])\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7354307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 24.9346\n",
      "Epoch 2 | Loss: 12.6128\n",
      "Epoch 3 | Loss: 12.2989\n",
      "Epoch 4 | Loss: 12.1123\n",
      "Epoch 5 | Loss: 12.0643\n",
      "Epoch 6 | Loss: 12.0297\n",
      "Epoch 7 | Loss: 11.9932\n",
      "Epoch 8 | Loss: 11.8993\n",
      "Epoch 9 | Loss: 11.8504\n",
      "Epoch 10 | Loss: 11.7794\n",
      "Epoch 11 | Loss: 11.6668\n",
      "Epoch 12 | Loss: 11.6035\n",
      "Epoch 13 | Loss: 11.3629\n",
      "Epoch 14 | Loss: 11.0382\n",
      "Epoch 15 | Loss: 10.7484\n",
      "Epoch 16 | Loss: 10.4378\n",
      "Epoch 17 | Loss: 10.1480\n",
      "Epoch 18 | Loss: 9.8811\n",
      "Epoch 19 | Loss: 9.6402\n",
      "Epoch 20 | Loss: 9.5021\n",
      "Epoch 21 | Loss: 9.2801\n",
      "Epoch 22 | Loss: 9.0711\n",
      "Epoch 23 | Loss: 9.0220\n",
      "Epoch 24 | Loss: 8.7932\n",
      "Epoch 25 | Loss: 8.6352\n",
      "Epoch 26 | Loss: 8.4809\n",
      "Epoch 27 | Loss: 8.3612\n",
      "Epoch 28 | Loss: 8.2001\n",
      "Epoch 29 | Loss: 8.0328\n",
      "Epoch 30 | Loss: 7.9407\n",
      "Epoch 31 | Loss: 7.7732\n",
      "Epoch 32 | Loss: 7.6529\n",
      "Epoch 33 | Loss: 7.5855\n",
      "Epoch 34 | Loss: 7.4327\n",
      "Epoch 35 | Loss: 7.3371\n",
      "Epoch 36 | Loss: 7.2560\n",
      "Epoch 37 | Loss: 7.1589\n",
      "Epoch 38 | Loss: 7.0817\n",
      "Epoch 39 | Loss: 6.9631\n",
      "Epoch 40 | Loss: 6.9172\n",
      "Epoch 41 | Loss: 6.8014\n",
      "Epoch 42 | Loss: 6.8098\n",
      "Epoch 43 | Loss: 6.5763\n",
      "Epoch 44 | Loss: 6.5113\n",
      "Epoch 45 | Loss: 6.3671\n",
      "Epoch 46 | Loss: 6.3796\n",
      "Epoch 47 | Loss: 6.2476\n",
      "Epoch 48 | Loss: 6.1917\n",
      "Epoch 49 | Loss: 6.0493\n",
      "Epoch 50 | Loss: 5.9479\n",
      "Epoch 51 | Loss: 5.8347\n",
      "Epoch 52 | Loss: 5.6824\n",
      "Epoch 53 | Loss: 5.6464\n",
      "Epoch 54 | Loss: 5.5225\n",
      "Epoch 55 | Loss: 5.3707\n",
      "Epoch 56 | Loss: 5.3215\n",
      "Epoch 57 | Loss: 5.2981\n",
      "Epoch 58 | Loss: 5.0825\n",
      "Epoch 59 | Loss: 5.0250\n",
      "Epoch 60 | Loss: 4.9363\n",
      "Epoch 61 | Loss: 4.8281\n",
      "Epoch 62 | Loss: 4.7560\n",
      "Epoch 63 | Loss: 4.7288\n",
      "Epoch 64 | Loss: 4.5029\n",
      "Epoch 65 | Loss: 4.4822\n",
      "Epoch 66 | Loss: 4.4259\n",
      "Epoch 67 | Loss: 4.1691\n",
      "Epoch 68 | Loss: 4.1557\n",
      "Epoch 69 | Loss: 4.0087\n",
      "Epoch 70 | Loss: 4.0594\n",
      "Epoch 71 | Loss: 3.9804\n",
      "Epoch 72 | Loss: 3.8776\n",
      "Epoch 73 | Loss: 3.6849\n",
      "Epoch 74 | Loss: 3.8312\n",
      "Epoch 75 | Loss: 3.5398\n",
      "Epoch 76 | Loss: 3.5515\n",
      "Epoch 77 | Loss: 3.4229\n",
      "Epoch 78 | Loss: 3.3990\n",
      "Epoch 79 | Loss: 3.2622\n",
      "Epoch 80 | Loss: 3.2255\n",
      "Epoch 81 | Loss: 3.3294\n",
      "Epoch 82 | Loss: 4.0045\n",
      "Epoch 83 | Loss: 3.2302\n",
      "Epoch 84 | Loss: 2.8223\n",
      "Epoch 85 | Loss: 2.8733\n",
      "Epoch 86 | Loss: 2.8229\n",
      "Epoch 87 | Loss: 2.6862\n",
      "Epoch 88 | Loss: 2.8152\n",
      "Epoch 89 | Loss: 2.6628\n",
      "Epoch 90 | Loss: 2.7405\n",
      "Epoch 91 | Loss: 2.5083\n",
      "Epoch 92 | Loss: 2.4646\n",
      "Epoch 93 | Loss: 2.5256\n",
      "Epoch 94 | Loss: 2.4333\n",
      "Epoch 95 | Loss: 2.4154\n",
      "Epoch 96 | Loss: 2.1029\n",
      "Epoch 97 | Loss: 2.5315\n",
      "Epoch 98 | Loss: 2.2277\n",
      "Epoch 99 | Loss: 2.1533\n",
      "Epoch 100 | Loss: 2.1377\n",
      "Epoch 101 | Loss: 2.2365\n",
      "Epoch 102 | Loss: 2.3086\n",
      "Epoch 103 | Loss: 1.9585\n",
      "Epoch 104 | Loss: 2.1113\n",
      "Epoch 105 | Loss: 1.7566\n",
      "Epoch 106 | Loss: 2.2177\n",
      "Epoch 107 | Loss: 2.0263\n",
      "Epoch 108 | Loss: 1.8982\n",
      "Epoch 109 | Loss: 1.8685\n",
      "Epoch 110 | Loss: 1.6972\n",
      "Epoch 111 | Loss: 1.7957\n",
      "Epoch 112 | Loss: 2.0596\n",
      "Epoch 113 | Loss: 1.6102\n",
      "Epoch 114 | Loss: 1.4608\n",
      "Epoch 115 | Loss: 1.8069\n",
      "Epoch 116 | Loss: 2.3553\n",
      "Epoch 117 | Loss: 1.3222\n",
      "Epoch 118 | Loss: 1.2187\n",
      "Epoch 119 | Loss: 1.8829\n",
      "Epoch 120 | Loss: 1.7890\n",
      "Epoch 121 | Loss: 1.4810\n",
      "Epoch 122 | Loss: 1.4269\n",
      "Epoch 123 | Loss: 1.3823\n",
      "Epoch 124 | Loss: 1.6569\n",
      "Epoch 125 | Loss: 1.4379\n",
      "Epoch 126 | Loss: 1.3405\n",
      "Epoch 127 | Loss: 1.6984\n",
      "Epoch 128 | Loss: 1.3780\n",
      "Epoch 129 | Loss: 1.2053\n",
      "Epoch 130 | Loss: 1.4882\n",
      "Epoch 131 | Loss: 1.7191\n",
      "Epoch 132 | Loss: 1.1415\n",
      "Epoch 133 | Loss: 1.7385\n",
      "Epoch 134 | Loss: 1.1144\n",
      "Epoch 135 | Loss: 0.9543\n",
      "Epoch 136 | Loss: 1.1233\n",
      "Epoch 137 | Loss: 2.0189\n",
      "Epoch 138 | Loss: 1.1125\n",
      "Epoch 139 | Loss: 1.0132\n",
      "Epoch 140 | Loss: 1.6890\n",
      "Epoch 141 | Loss: 1.1582\n",
      "Epoch 142 | Loss: 1.0102\n",
      "Epoch 143 | Loss: 1.1478\n",
      "Epoch 144 | Loss: 1.5549\n",
      "Epoch 145 | Loss: 1.0426\n",
      "Epoch 146 | Loss: 1.0480\n",
      "Epoch 147 | Loss: 1.1598\n",
      "Epoch 148 | Loss: 0.8393\n",
      "Epoch 149 | Loss: 1.4393\n",
      "Epoch 150 | Loss: 1.5845\n",
      "Epoch 151 | Loss: 0.9593\n",
      "Epoch 152 | Loss: 0.6706\n",
      "Epoch 153 | Loss: 0.9837\n",
      "Epoch 154 | Loss: 1.7591\n",
      "Epoch 155 | Loss: 1.4216\n",
      "Epoch 156 | Loss: 0.7730\n",
      "Epoch 157 | Loss: 0.9581\n",
      "Epoch 158 | Loss: 2.0571\n",
      "Epoch 159 | Loss: 0.7793\n",
      "Epoch 160 | Loss: 0.4869\n",
      "Epoch 161 | Loss: 0.5473\n",
      "Epoch 162 | Loss: 0.7897\n",
      "Epoch 163 | Loss: 2.0153\n",
      "Epoch 164 | Loss: 1.5921\n",
      "Epoch 165 | Loss: 0.9162\n",
      "Epoch 166 | Loss: 0.6647\n",
      "Epoch 167 | Loss: 0.8355\n",
      "Epoch 168 | Loss: 1.1267\n",
      "Epoch 169 | Loss: 0.9243\n",
      "Epoch 170 | Loss: 1.5144\n",
      "Epoch 171 | Loss: 1.0213\n",
      "Epoch 172 | Loss: 0.7191\n",
      "Epoch 173 | Loss: 0.6975\n",
      "Epoch 174 | Loss: 1.7479\n",
      "Epoch 175 | Loss: 1.2433\n",
      "Epoch 176 | Loss: 0.5307\n",
      "Epoch 177 | Loss: 0.3714\n",
      "Epoch 178 | Loss: 0.3369\n",
      "Epoch 179 | Loss: 0.6083\n",
      "Epoch 180 | Loss: 4.3333\n",
      "Epoch 181 | Loss: 1.2920\n",
      "Epoch 182 | Loss: 0.5790\n",
      "Epoch 183 | Loss: 0.3898\n",
      "Epoch 184 | Loss: 0.3231\n",
      "Epoch 185 | Loss: 0.3353\n",
      "Epoch 186 | Loss: 0.3452\n",
      "Epoch 187 | Loss: 3.3822\n",
      "Epoch 188 | Loss: 1.1304\n",
      "Epoch 189 | Loss: 0.6525\n",
      "Epoch 190 | Loss: 0.4452\n",
      "Epoch 191 | Loss: 0.3925\n",
      "Epoch 192 | Loss: 1.1500\n",
      "Epoch 193 | Loss: 1.6191\n",
      "Epoch 194 | Loss: 0.6754\n",
      "Epoch 195 | Loss: 0.4391\n",
      "Epoch 196 | Loss: 0.3744\n",
      "Epoch 197 | Loss: 1.2945\n",
      "Epoch 198 | Loss: 2.3172\n",
      "Epoch 199 | Loss: 0.7376\n",
      "Epoch 200 | Loss: 0.4080\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DigitToStrokeLSTM().to(device)\n",
    "dx_dy_loss_fn = nn.MSELoss()\n",
    "eos_eod_loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (dig, input_seq, output_seq) in loader:\n",
    "        # stroke_seq: [batch, seq_len, 4]\n",
    "        input_seq = input_seq.to(device)\n",
    "        target_seq = output_seq.to(device)\n",
    "        dig = dig.to(device)\n",
    "\n",
    "        pred_seq, hidden = model(input_seq, onehot_digit = dig)  # [batch, seq_len-1, 4]\n",
    "\n",
    "        # Separate predictions\n",
    "        pred_dxdy = pred_seq[..., :2]         # [batch, seq_len-1, 2]\n",
    "        pred_eos_eod = pred_seq[..., 2:]      # [batch, seq_len-1, 2]\n",
    "\n",
    "        # Separate targets\n",
    "        target_dxdy = target_seq[..., :2]\n",
    "        target_eos_eod = target_seq[..., 2:]\n",
    "\n",
    "        # Compute losses\n",
    "        loss_dxdy = dx_dy_loss_fn(pred_dxdy, target_dxdy)\n",
    "        loss_eos_eod = eos_eod_loss_fn(pred_eos_eod, target_eos_eod)\n",
    "\n",
    "        loss = loss_dxdy + loss_eos_eod\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0d776b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(number):\n",
    "    model.eval()\n",
    "    \n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[number] = 1\n",
    "    temp_onehot = torch.tensor(temp_onehot, dtype=torch.float32).to(device)\n",
    "    \n",
    "    initial_input = torch.tensor([0, 0, 0, 0], dtype=torch.float32).to(device).unsqueeze(0).unsqueeze(1)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    output, hidden = model(initial_input, onehot_digit=temp_onehot)\n",
    "    output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "\n",
    "    outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "\n",
    "    for i in range(max_length-1):\n",
    "        output, hidden = model(output, hidden=hidden)\n",
    "        output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "        outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "        \n",
    "        print(outputs[-1])\n",
    "        if output[:, -1, 3] == 1:\n",
    "            print(\"HI\")\n",
    "            break\n",
    "    \n",
    "    draw_stroke_sequence(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e548538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02091348  0.02303193  0.          0.        ]\n",
      "[-0.02793229  0.02641897  0.          0.        ]\n",
      "[-0.01556922  0.03228036  0.          0.        ]\n",
      "[-0.01989558  0.02915207  0.          0.        ]\n",
      "[-0.02250019  0.0274365   0.          0.        ]\n",
      "[-0.02005631  0.03285306  0.          0.        ]\n",
      "[-0.01585633  0.02295684  0.          0.        ]\n",
      "[-0.0195017   0.02797204  0.          0.        ]\n",
      "[-0.00615801  0.0237554   0.          0.        ]\n",
      "[-0.01109815  0.02214557  0.          0.        ]\n",
      "[-0.0019067   0.02258555  0.          0.        ]\n",
      "[0.00415656 0.02451112 0.         0.        ]\n",
      "[0.00969955 0.02092079 0.         0.        ]\n",
      "[0.01810037 0.01651934 0.         0.        ]\n",
      "[0.02084279 0.01393953 0.         0.        ]\n",
      "[0.01891702 0.01251896 0.         0.        ]\n",
      "[0.01526223 0.0140835  0.         0.        ]\n",
      "[0.01124618 0.01802234 0.         0.        ]\n",
      "[0.01673268 0.02590291 0.         0.        ]\n",
      "[0.01763134 0.02312748 0.         0.        ]\n",
      "[0.01935775 0.01697342 0.         0.        ]\n",
      "[0.01516449 0.01300884 0.         0.        ]\n",
      "[0.01608093 0.00358598 0.         0.        ]\n",
      "[ 0.02137532 -0.00320823  0.          0.        ]\n",
      "[ 0.02211796 -0.01127938  0.          0.        ]\n",
      "[ 0.01971053 -0.0183751   0.          0.        ]\n",
      "[ 0.01943785 -0.03094944  0.          0.        ]\n",
      "[ 0.01107357 -0.03804079  0.          0.        ]\n",
      "[-0.0024694  -0.03928471  0.          0.        ]\n",
      "[-0.01575722 -0.02576577  0.          0.        ]\n",
      "[-0.03091868 -0.00981903  0.          0.        ]\n",
      "[-0.03459473 -0.00528157  0.          0.        ]\n",
      "[-0.0232907  -0.01146523  0.          0.        ]\n",
      "[-0.0258281  -0.01298453  0.          0.        ]\n",
      "[-0.02258402 -0.01176841  0.          0.        ]\n",
      "[-0.02073958 -0.01545095  0.          0.        ]\n",
      "[-0.01465608 -0.02242445  0.          0.        ]\n",
      "[-0.00871929 -0.03035992  0.          0.        ]\n",
      "[-0.00521002 -0.05028987  1.          1.        ]\n",
      "HI\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ac7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
