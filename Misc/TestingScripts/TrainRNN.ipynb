{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b20e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447d8c",
   "metadata": {},
   "source": [
    "# Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e30563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for i in range(10000):\n",
    "    try:\n",
    "        data = np.loadtxt(f'../sequences/testimg-{i}-targetdata.txt', delimiter=' ')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File not found at path: {i}\")\n",
    "        continue\n",
    "    \n",
    "    inputOneshot = data[0, 0:10]\n",
    "    outputStrokes = data[:, 10:]\n",
    "    outputStrokes[:, 0] = outputStrokes[:, 0]/28\n",
    "    outputStrokes[:, 1] = outputStrokes[:, 1]/28\n",
    "    \n",
    "    \n",
    "    input_data.append(inputOneshot)\n",
    "    output_data.append(outputStrokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74adda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stroke_sequence(sequence, save_path=None, show=True):\n",
    "    \"\"\"\n",
    "    sequence: numpy array or list of shape (T, 4) where each row is [dx, dy, eos, eod]\n",
    "    save_path: optional path to save the plot as an image\n",
    "    show: whether to display the plot\n",
    "    \"\"\"\n",
    "    x, y = 0, 0\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for dx, dy, eos, eod in sequence:\n",
    "        x += dx*28\n",
    "        y += dy*28\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if eos > 0.5:  # end of stroke\n",
    "            xs.append(None)\n",
    "            ys.append(None)\n",
    "\n",
    "        if eod > 0.5:\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.plot(xs, ys, linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bc965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumFromOneHot(inp):\n",
    "    for i in range(10):\n",
    "        if inp[i] == 1:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84ec919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_stroke_sequence(output_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04766e4",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd2c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Finding the max length of a sequence\n",
    "max_length = 0\n",
    "j = 0\n",
    "for i in range(len(output_data)):\n",
    "    if len(output_data[i]) > max_length:\n",
    "        max_length = len(output_data[i])\n",
    "    j += 1\n",
    "\n",
    "print(max_length)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edeec1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642bf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the sequences so that they are all the same size (good for batching)\n",
    "padded_output_data = np.zeros( (len(output_data), max_length, 4) )\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    padded_output_data[i, :len(output_data[i]), :] = output_data[i]\n",
    "    padded_output_data[i, len(output_data[i]):, :] = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cfe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_data = np.zeros( (len(output_data), max_length, 4) )\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    padded_input_data[i, 0, :] = [0, 0, 0, 0]\n",
    "    padded_input_data[i, 1:, :] = padded_output_data[i, :max_length-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8523173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, onehot, inputs, outputstroke):\n",
    "        self.digit = onehot                     # shape: [N]\n",
    "        self.inputstroke = inputs               # list of [seq_len, 4] arrays\n",
    "        self.outputstroke = outputstroke        # list of [seq_len, 4] arrays\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.digit)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        digit = self.digit[idx]\n",
    "        inputs = self.inputstroke[idx]\n",
    "        outputs = self.outputstroke[idx]\n",
    "        return torch.tensor(digit, dtype=torch.float32), torch.tensor(inputs, dtype=torch.float32), torch.tensor(outputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1171d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokeDataset = StrokeDataset(input_data, padded_input_data, padded_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67af144",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(strokeDataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8f994",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2082a2d",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "\n",
    "RNN:\n",
    "input_size = output_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58d8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitToStrokeLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, num_layers=2, batch_size=32):\n",
    "        super(DigitToStrokeLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Linear(10, hidden_size)  # From one-hot to hidden dim\n",
    "        \n",
    "        # LSTM\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        # Inital hidden state is the one-hot of number\n",
    "        # Initial input is [0, 0, 0, 0, 0]\n",
    "        # Input at t > 0 is output from t-1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=4,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        self.output_head = nn.Linear(hidden_size, 4)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.sigmoid = nn.Sigmoid()  # For eos/eod\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None, onehot_digit=None):\n",
    "        \n",
    "        if onehot_digit != None and hidden == None:\n",
    "            # Embed the digit\n",
    "            h0 = self.embedding(onehot_digit)\n",
    "            h0 = h0.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "            c0 = torch.zeros_like(h0)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        elif hidden == None and onehot_digit == None:\n",
    "            hidden = (torch.zeros(self.num_layers, self.batch_size, self.hidden_size),\n",
    "                      torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "            \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        out = self.output_head(out)\n",
    "        \n",
    "        out[:, :, 0:2] = self.tanh(out[:, :, 0:2])\n",
    "        # out[:, :, 2:] = self.sigmoid(out[:, :, 2:])\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAMAGE WEIGHTS\n",
    "\n",
    "def damage_smallest(model, p_smallest): # energy constraint\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_smallest == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            weight_magnitudes = tensor.abs().view(-1)\n",
    "            k = int(weight_magnitudes.numel() * p_smallest)\n",
    "\n",
    "            if k == 0:\n",
    "                continue\n",
    "            threshold = weight_magnitudes.kthvalue(k).values.item()\n",
    "\n",
    "            mask = tensor.abs() >= threshold\n",
    "            param.data.mul_(mask)\n",
    "\n",
    "def damage_fas(model,  p_block, p_reflect, p_filter):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_block + p_reflect + p_filter == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            flat_weights = tensor.view(-1)\n",
    "            nonzero_indices = (flat_weights!=0).nonzero(as_tuple=True)[0]\n",
    "            num_nonzero_indices = nonzero_indices.numel()\n",
    "            if num_nonzero_indices == 0:\n",
    "                continue\n",
    "\n",
    "            # percentage of weights damaged will be taken from the number of nonzero weights\n",
    "            # simulated fas damage occurs after energy constraint blockage\n",
    "            num_block = int(num_nonzero_indices * p_block)\n",
    "            num_reflect = int(num_nonzero_indices * p_reflect)\n",
    "            num_filter = int(num_nonzero_indices * p_filter)\n",
    "\n",
    "            shuffled_indices = nonzero_indices[torch.randperm(num_nonzero_indices, device=flat_weights.device)]\n",
    "\n",
    "            indices_block = shuffled_indices[:num_block]\n",
    "            indices_reflect = shuffled_indices[num_block:num_block+num_reflect]\n",
    "            indices_filter = shuffled_indices[num_block+num_reflect:num_block+num_reflect+num_filter]\n",
    "\n",
    "            # do damage\n",
    "            # blockage: set weights to 0\n",
    "            if p_block != 0:\n",
    "                flat_weights[indices_block] = 0\n",
    "\n",
    "            # reflect: halve weights\n",
    "            if p_reflect != 0:\n",
    "                flat_weights[indices_reflect] *= 0.5\n",
    "\n",
    "            # filter: low pass filter (lusch et al)\n",
    "            if p_filter != 0:\n",
    "                weights_to_filter = flat_weights[indices_filter]            # get weights before transformation\n",
    "                signs = torch.sign(weights_to_filter)                       # get signs of weights\n",
    "                abs_weights_to_filter = weights_to_filter.abs()             # get high_weight, should be in the 95th percentile for all weights\n",
    "                high_weight = torch.quantile(flat_weights.abs(), 0.95)      # scale weights to mostly between -1 and 1\n",
    "                x = abs_weights_to_filter / high_weight\n",
    "                transformed_weights = -0.2744 * x**2 + 0.9094 * x - 0.0192\n",
    "                gaussian_noise = torch.randn_like(transformed_weights) * 0.05\n",
    "                transformed_weights += gaussian_noise\n",
    "                transformed_weights = transformed_weights * signs * high_weight # rescale\n",
    "                flat_weights[indices_filter] = transformed_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7354307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 26.7294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m target_seq \u001b[38;5;241m=\u001b[39m output_seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m dig \u001b[38;5;241m=\u001b[39m dig\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 25\u001b[0m pred_seq, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monehot_digit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdig\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, seq_len-1, 4]\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Separate predictions\u001b[39;00m\n\u001b[0;32m     28\u001b[0m pred_dxdy \u001b[38;5;241m=\u001b[39m pred_seq[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m2\u001b[39m]         \u001b[38;5;66;03m# [batch, seq_len-1, 2]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kapj_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kapj_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[15], line 45\u001b[0m, in \u001b[0;36mDigitToStrokeLSTM.forward\u001b[1;34m(self, x, hidden, onehot_digit)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hidden \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m onehot_digit \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size),\n\u001b[0;32m     43\u001b[0m               torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[1;32m---> 45\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n\u001b[0;32m     47\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_head(out)\n",
      "File \u001b[1;32mc:\\Users\\kapj_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kapj_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\kapj_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DigitToStrokeLSTM().to(device)\n",
    "\n",
    "# # damage weights to simulate energy constraint and lesioning\n",
    "# damage_smallest(model, 0.0)\n",
    "# damage_fas(model, 0.0, 0.0, 0.0)\n",
    "\n",
    "dx_dy_loss_fn = nn.MSELoss()\n",
    "eos_eod_loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (dig, input_seq, output_seq) in loader:\n",
    "        # stroke_seq: [batch, seq_len, 4]\n",
    "        input_seq = input_seq.to(device)\n",
    "        target_seq = output_seq.to(device)\n",
    "        dig = dig.to(device)\n",
    "\n",
    "        pred_seq, hidden = model(input_seq, onehot_digit = dig)  # [batch, seq_len-1, 4]\n",
    "\n",
    "        # Separate predictions\n",
    "        pred_dxdy = pred_seq[..., :2]         # [batch, seq_len-1, 2]\n",
    "        pred_eos_eod = pred_seq[..., 2:]      # [batch, seq_len-1, 2]\n",
    "\n",
    "        # Separate targets\n",
    "        target_dxdy = target_seq[..., :2]\n",
    "        target_eos_eod = target_seq[..., 2:]\n",
    "\n",
    "        # Compute losses\n",
    "        loss_dxdy = dx_dy_loss_fn(pred_dxdy, target_dxdy)\n",
    "        loss_eos_eod = eos_eod_loss_fn(pred_eos_eod, target_eos_eod)\n",
    "\n",
    "        loss = loss_dxdy + loss_eos_eod\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0d776b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(number):\n",
    "    model.eval()\n",
    "    \n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[number] = 1\n",
    "    temp_onehot = torch.tensor(temp_onehot, dtype=torch.float32).to(device)\n",
    "    \n",
    "    initial_input = torch.tensor([0, 0, 0, 0], dtype=torch.float32).to(device).unsqueeze(0).unsqueeze(1)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    output, hidden = model(initial_input, onehot_digit=temp_onehot)\n",
    "    output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "\n",
    "    outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "\n",
    "    for i in range(max_length-1):\n",
    "        output, hidden = model(output, hidden=hidden)\n",
    "        output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "        outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "        \n",
    "        print(outputs[-1])\n",
    "        if output[:, -1, 3] == 1:\n",
    "            print(\"HI\")\n",
    "            break\n",
    "    \n",
    "    draw_stroke_sequence(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e548538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02091348  0.02303193  0.          0.        ]\n",
      "[-0.02793229  0.02641897  0.          0.        ]\n",
      "[-0.01556922  0.03228036  0.          0.        ]\n",
      "[-0.01989558  0.02915207  0.          0.        ]\n",
      "[-0.02250019  0.0274365   0.          0.        ]\n",
      "[-0.02005631  0.03285306  0.          0.        ]\n",
      "[-0.01585633  0.02295684  0.          0.        ]\n",
      "[-0.0195017   0.02797204  0.          0.        ]\n",
      "[-0.00615801  0.0237554   0.          0.        ]\n",
      "[-0.01109815  0.02214557  0.          0.        ]\n",
      "[-0.0019067   0.02258555  0.          0.        ]\n",
      "[0.00415656 0.02451112 0.         0.        ]\n",
      "[0.00969955 0.02092079 0.         0.        ]\n",
      "[0.01810037 0.01651934 0.         0.        ]\n",
      "[0.02084279 0.01393953 0.         0.        ]\n",
      "[0.01891702 0.01251896 0.         0.        ]\n",
      "[0.01526223 0.0140835  0.         0.        ]\n",
      "[0.01124618 0.01802234 0.         0.        ]\n",
      "[0.01673268 0.02590291 0.         0.        ]\n",
      "[0.01763134 0.02312748 0.         0.        ]\n",
      "[0.01935775 0.01697342 0.         0.        ]\n",
      "[0.01516449 0.01300884 0.         0.        ]\n",
      "[0.01608093 0.00358598 0.         0.        ]\n",
      "[ 0.02137532 -0.00320823  0.          0.        ]\n",
      "[ 0.02211796 -0.01127938  0.          0.        ]\n",
      "[ 0.01971053 -0.0183751   0.          0.        ]\n",
      "[ 0.01943785 -0.03094944  0.          0.        ]\n",
      "[ 0.01107357 -0.03804079  0.          0.        ]\n",
      "[-0.0024694  -0.03928471  0.          0.        ]\n",
      "[-0.01575722 -0.02576577  0.          0.        ]\n",
      "[-0.03091868 -0.00981903  0.          0.        ]\n",
      "[-0.03459473 -0.00528157  0.          0.        ]\n",
      "[-0.0232907  -0.01146523  0.          0.        ]\n",
      "[-0.0258281  -0.01298453  0.          0.        ]\n",
      "[-0.02258402 -0.01176841  0.          0.        ]\n",
      "[-0.02073958 -0.01545095  0.          0.        ]\n",
      "[-0.01465608 -0.02242445  0.          0.        ]\n",
      "[-0.00871929 -0.03035992  0.          0.        ]\n",
      "[-0.00521002 -0.05028987  1.          1.        ]\n",
      "HI\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ac7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
