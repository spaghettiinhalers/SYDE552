{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b20e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447d8c",
   "metadata": {},
   "source": [
    "# Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965b3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumFromOneHot(inp):\n",
    "    for i in range(10):\n",
    "        if inp[i] == 1:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69400a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stroke_sequence(sequence, save_path=None, show=True):\n",
    "    \"\"\"\n",
    "    sequence: numpy array or list of shape (T, 4) where each row is [dx, dy, eos, eod]\n",
    "    save_path: optional path to save the plot as an image\n",
    "    show: whether to display the plot\n",
    "    \"\"\"\n",
    "    x, y = 0, 0\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for dx, dy, eos, eod in sequence:\n",
    "        x += dx*28\n",
    "        y += dy*28\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if eos > 0.5:  # end of stroke\n",
    "            xs.append(None)\n",
    "            ys.append(None)\n",
    "\n",
    "        if eod > 0.5:\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.plot(xs, ys, linewidth=2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08ded58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [[] for _ in range(10)]\n",
    "\n",
    "for i in range(10000):\n",
    "    try:\n",
    "        data = np.loadtxt(f'../sequences/testimg-{i}-targetdata.txt', delimiter=' ')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found at path: {i}\")\n",
    "        continue\n",
    "    \n",
    "    inputOneshot = data[0, 0:10]\n",
    "    outputStrokes = data[:, 10:]\n",
    "    outputStrokes[:, 0] = outputStrokes[:, 0]/28\n",
    "    outputStrokes[:, 1] = outputStrokes[:, 1]/28\n",
    "    \n",
    "    datas[getNumFromOneHot(inputOneshot)].append(outputStrokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e460841",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input_data = []\n",
    "temp_output_data = []\n",
    "\n",
    "for i in range(10):\n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[i] = 1\n",
    "    \n",
    "    smallest_10 = sorted(datas[i], key=lambda x: len(x[1]))[:100]\n",
    "    for k in smallest_10:\n",
    "        temp_input_data.append(temp_onehot)\n",
    "        temp_output_data.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c84ec919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAACuCAYAAABAzl3QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJqElEQVR4nO3dfXAUdx3H8c9e7nJ5ToiEBPIEdQwk0ATDQ6NThw5apkKnaitVirGAxRkdp/pHZ8qUf/iDcXSG6R/adjptMdURQceiU1un49h2qqYGUog0QJia8pTEPDQQ7iDPuVv/SBPCsUfuYX+79939vP5KZu9ufxxvlt/u7e5puq7rIBLIY/cAiBLFeEksxktiMV4Si/GSWIyXxGK8JBbjJbEYL4nFeEksxktiMV4Si/GSWIyXxGK8JBbjJbEYL4nFeEksr90DcIuLg8N4/t1OXB2eULqeLL8XjQ2VWL+sUOl6UoHGa9is8eThNrx+6n+WrMvr0fDC9npsWlliyfrswmmDRQauj1m2rqmwjh8eOom/nemzbJ124LTBBu/v2YgMX5rpr6vrOva/2YE/tfXMBuzkLTDjtUFhdrqSeAHgwNY6AHBFwJw2OEyaR8OBrXX4xudLATh7CsF4HcgtATNeh3JDwJzzxqijN4gPLg0l/Pz+4LiJo4nNTMCAM+fAjDcGl6+MYPMv/gmJR8SdHDCnDTE42xswLdwVJbnwe6192506heCWN05bahdj4/JFCT3X5/XgvuVF0DTN5FHNz4lbYMYbp9rSfDyypszuYSTEaQFz2uAyTppCMF4XckrAjNelnBAw57yfGh6fwtCI8bm2gzfUnoNrl2hz4Ge/tRr1FQVRn5fr9yE/y2fRKKNjvACaOwex+zcfYGQiZPdQLGcU8JOH2+74HK9Hw/6vr8K311dYMcSoOG0A8MaHvTGHW5KfoXg01oucQsxnKqzjaFuP4lHNj1teAOHwzU8gNlQVITfD+G2pXpyHB1bJO6QUi5mA6ysX4Nj5K4aP0XXgzfZeALe+Z3ZhvBH2bqlGVXGu3cOwRZpHQ2NDJRobKg2Xh8L6bLypgNMGEovxkliMl8RivCSWK3bY/n62H798txMj41OGy/uC1l2WTuZxRbw/e+scOgduxPTYTEVX9ZL5XBFvcHRy9uccv/EfWdOAh+qWoLwwy6phUZJcEe+M0oJMNO/ZaPcwyCTcYSOxGC+JxXhJLMZLYonfYesLjOFXzRcAAPUVBXhg1WKbR+QOXUMj+OlfOwyXeT0aHqxdgpoleUrHID7eK8PjeOkf5wEA2++pYLwW6Q/efN+NvHayG81Pb4Q3Td1/7pw2UMzSPBo2VBXF9Nj+4DhGJ9VemSJ+yxuLl767FpOhMNIVbgXcomnHOrT3BDARChsu3//GWZzqDlgyFlfEu7q8wO4hOIbHo6HuDu9nXqZ1F2ZyU0RiMV4Si/GSWIyXxBIf78B16+84TqlBdLzt3QH8eM7dXe4qyrFxNGQ1sfG2dwew/ZUWBMemL+1Zv7QQ29aX2zwqspLIeI3Cbdq5DlnprjhsTZ8SF2+0cLOjXN5DziUqXoZLc4mJl+FSJBHxMlwykvLxMlyKJqXjZbh0JykbL8Ol+aRkCbeFu6wQTTsYLt0q5ba8DJdilVLxMlyKR8rEy3ApXikRL8OlRNgeb0dvkOFSQmyP97l3OhkuJcT2ePvn3FL/4ONrGS7FzPZ45+L5uBSPlIqXKB6Ml8RivCQW4yWxGC+JZWu8wbFJ9Ab47ZNO9VF/bF/cmCjb4g2OTaLx4HH0XBsFAKxckgePZtdoyCx1ZQWzP+9sOo52hffqtSXemXBPdV0DABRmp+PZR1dD01ivdD+477NYv6wQABAcm8L2V1qUBWx5vEbhHt7dgOUluVYPhRTI9nvRtGOdJQFbGi/DdQerArYsXobrLlYEbEm8DNedVAesPF6G624qA1Ye70+O/IfhupxRwN85eAyB0cmkXldpvCMTU3jn3AAAoCDLx3BdLNvvxe4v3TX7e2B0Ep0DyX2IoTTeUFif/fnu0nyG62LNnYP40e9Ozv6+qaYY9RUFSb0mz20g5Zo7B7Hr1VaMT01/a+b9NcV47rH6pD+UYryklFG4zz9Wj3Rv8ukxXlJGZbgA4yVFVIcLMF5SwIpwgSTvEjkVCmPfX87gxKVrhsvDc442kDu0XR6yJFwgyXibP76C37ZcjumxGb60ZFZFQhz81wVLwgWSjHfuJyRej4a0KGeTL8zxY8cXlyazKhJibhMHvlmnLFzAxJtLP7O5GrvuXWbWy5EDeBTvUXGHjcRivCQW4yWxGC+JxXhJLMZLYjFeEovxkliMl8RivCQW4yWxGC+Jxa/fobiEwjpO9wQwEQobLg8meS+GeDBeisuuV1vx3kef2D0MAJw2UBxCYT3mcIvz/MhUfAECt7yUkOI8P762utRwmS9Nw4O1S+BNU7ttZLyUkPIFWXhmc7WtY+C0gcRivCQW4yWxGC+JZdoOW1jnDUakGwiOYc/Rdhy/cNVwuZ5if8dJxZuXcfPpL753HhuqivC5Yt6DV6KB4Bi2vdyCjz8ZjunxeZk+xSOan6Yn8c9pMhTGwy+8j/ae6e8XWJjjx+Hd9zBgYSLDzc/0YVGuP+rjF2SnY89XV6C+YoFVQzSUVLwAEBiZxPaDLTjdEwTAgKWJDLe0IBNHvt+A8sIsm0c2v6R32PKzfDj0vQasKs0DAAzeGMe2l4/hv/3Xkx4cqSU5XMCkow0MWB7p4QImHipjwHI4IVzA5OO8DDj1OSVcwIQdNiPciYvf8PgUmpov4Fyf2n/op7qvoevqKADZ4QKK4gUYcDyGx6ews6kVxy8afziggvRwAYUfD3MKERs7wl1Rkis+XEDhlncGt8DRRYabl+HFi41rUKEwKo+mYXF+RtJf4JcKlMcLMGAjRuEeeqIBd5fl2zwyOSw5q4xTiFsxXHNYdkokA57GcM1j6fm8bg+Y4ZrLkjlvJKM58FObquC7w9Wm65YWouIz9u0dXxwcxolLQ0m9xu9buxiuiWyJF7g94Plo2vT3ej2ypkzxyG73h9YuPH30Q5j1TjFcc9h2GVDkFGI+ug489cdTeO1Et+KR3Yrhpi7btrwzxiZDeLtjAFdHJqI+pu3yEI6e7AFg7RY4Mtyta8pQW16Q8Oulp2n4cnUxFuZEP9GbYmd7vLHQdR37Xj+DX//7EgBrAo4M94l7l2HvlmpHHNx3ChFXD2uahn0PrcTjX6gEoH4KwXBlEBEvYF3ADFcOMfEC6gNmuLKImPNGMpoD//zhWnylpjjh13zrdB/2/rmd4QoiMl7g9oDNxHBlEDVtmCtyCmEWhiuH2C3vDF3XcaS1C293DCR1OyJN03B/zSI8urac4QohPl5yL7HTBiLGS2IxXhKL8ZJYjJfEYrwkFuMlsRgvicV4SSzGS2IxXhKL8ZJYjJfEYrwkFuMlsRgvicV4SSzGS2L9H037/vL0nMyGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_stroke_sequence(temp_output_data[22])\n",
    "\n",
    "# 0: [0, 3, 5, 10, 12, 16, 18, 20, 21, 22]\n",
    "# 1: [100, 101, 102, 103, 104, 105, 107, 109, 110, 112]\n",
    "# 2: [213, 218, 221, 230, 232, 234, 241, 249, 253, 254]\n",
    "# 3; [314, 325, 327, 345, 347, 350, 354, 358, 365, 366]\n",
    "# 4: [403, 405, 414, 415, 430, 434, 438, 439, 450, 464]\n",
    "# 5: [500, 524, 527, 531, 532, 545, 549, 558, 565, 569]\n",
    "# 6: [625, 627, 628, 643, 659, 661, 671, 676, 679 ,682]\n",
    "# 7: [712, 714, 723, 727, 729, 730, 736, 782, 795, 799]\n",
    "# 8: [820, 828, 839, 866, 870, 873, 874, 875, 877, 883]\n",
    "# 9: [908, 911, 922, 950, 952, 954, 956, 958, 962, 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dd22b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input_data = []\n",
    "temp_output_data = []\n",
    "\n",
    "for i in range(10):\n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[i] = 1\n",
    "    \n",
    "    smallest_10 = sorted(datas[i], key=lambda x: len(x[1]))[:100]\n",
    "    for k in smallest_10:\n",
    "        temp_input_data.append(temp_onehot)\n",
    "        temp_output_data.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e96a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "indexes = [0, 3, 5, 10, 12, 16, 18, 20, 21, 22, 100, 101, 102, 103, 104, 105, 107, 109, 110, 112, 213, 218, 221, 230, 232, 234, 241, 249, 253, 254, 314, 325, 327, 345, 347, 350, 354, 358, 365, 366,\n",
    "           403, 405, 414, 415, 430, 434, 438, 439, 450, 464, 500, 524, 527, 531, 532, 545, 549, 558, 565, 569, 625, 627, 628, 643, 659, 661, 671, 676, 679 ,682, 712, 714, 723, 727, 729, 730, 736, 782, 795, 799,\n",
    "           820, 828, 839, 866, 870, 873, 874, 875, 877, 883, 908, 911, 922, 950, 952, 954, 956, 958, 962, 999]\n",
    "\n",
    "input_data = [temp_input_data[i] for i in indexes]\n",
    "output_data = [temp_output_data[i] for i in indexes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04766e4",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cd2c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Finding the max length of a sequence\n",
    "max_length = 0\n",
    "j = 0\n",
    "for i in range(len(output_data)):\n",
    "    if len(output_data[i]) > max_length:\n",
    "        max_length = len(output_data[i])\n",
    "    j += 1\n",
    "\n",
    "print(max_length)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edeec1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "642bf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the sequences so that they are all the same size (good for batching)\n",
    "padded_output_data = np.zeros( (len(output_data), max_length, 4) )\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    padded_output_data[i, :len(output_data[i]), :] = output_data[i]\n",
    "    padded_output_data[i, len(output_data[i]):, :] = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37cfe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_data = np.zeros( (len(output_data), max_length, 4) )\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    padded_input_data[i, 0, :] = [0, 0, 0, 0]\n",
    "    padded_input_data[i, 1:, :] = padded_output_data[i, :max_length-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8523173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, onehot, inputs, outputstroke):\n",
    "        self.digit = onehot                     # shape: [N]\n",
    "        self.inputstroke = inputs               # list of [seq_len, 4] arrays\n",
    "        self.outputstroke = outputstroke        # list of [seq_len, 4] arrays\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.digit)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        digit = self.digit[idx]\n",
    "        inputs = self.inputstroke[idx]\n",
    "        outputs = self.outputstroke[idx]\n",
    "        return torch.tensor(digit, dtype=torch.float32), torch.tensor(inputs, dtype=torch.float32), torch.tensor(outputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1171d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokeDataset = StrokeDataset(input_data, padded_input_data, padded_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d67af144",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(strokeDataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8f994",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2082a2d",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "\n",
    "RNN:\n",
    "input_size = output_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e58d8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitToStrokeLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, num_layers=2, batch_size=32):\n",
    "        super(DigitToStrokeLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Linear(10, hidden_size)  # From one-hot to hidden dim\n",
    "        \n",
    "        # LSTM\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        # Inital hidden state is the one-hot of number\n",
    "        # Initial input is [0, 0, 0, 0, 0]\n",
    "        # Input at t > 0 is output from t-1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=4,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        # Output layer: predicts [dx, dy, eos, eod]\n",
    "        self.output_head = nn.Linear(hidden_size, 4)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.sigmoid = nn.Sigmoid()  # For eos/eod\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None, onehot_digit=None):\n",
    "        \n",
    "        if onehot_digit != None and hidden == None:\n",
    "            # Embed the digit\n",
    "            h0 = self.embedding(onehot_digit)\n",
    "            h0 = h0.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "            c0 = torch.zeros_like(h0)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        elif hidden == None and onehot_digit == None:\n",
    "            hidden = (torch.zeros(self.num_layers, self.batch_size, self.hidden_size),\n",
    "                      torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "            \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        out = self.output_head(out)\n",
    "        \n",
    "        out[:, :, 0:2] = self.tanh(out[:, :, 0:2])\n",
    "        # out[:, :, 2:] = self.sigmoid(out[:, :, 2:])\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185379e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAMAGE WEIGHTS\n",
    "\n",
    "def damage_smallest(model, p_smallest): # energy constraint\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_smallest == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            weight_magnitudes = tensor.abs().view(-1)\n",
    "            k = int(weight_magnitudes.numel() * p_smallest)\n",
    "\n",
    "            if k == 0:\n",
    "                continue\n",
    "            threshold = weight_magnitudes.kthvalue(k).values.item()\n",
    "\n",
    "            mask = tensor.abs() >= threshold\n",
    "            param.data.mul_(mask)\n",
    "\n",
    "def damage_fas(model,  p_block, p_reflect, p_filter):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.ndim >= 2:\n",
    "            if p_block + p_reflect + p_filter == 0:\n",
    "                continue\n",
    "\n",
    "            tensor = param.data\n",
    "            flat_weights = tensor.view(-1)\n",
    "            nonzero_indices = (flat_weights!=0).nonzero(as_tuple=True)[0]\n",
    "            num_nonzero_indices = nonzero_indices.numel()\n",
    "            if num_nonzero_indices == 0:\n",
    "                continue\n",
    "\n",
    "            # percentage of weights damaged will be taken from the number of nonzero weights\n",
    "            # simulated fas damage occurs after energy constraint blockage\n",
    "            num_block = int(num_nonzero_indices * p_block)\n",
    "            num_reflect = int(num_nonzero_indices * p_reflect)\n",
    "            num_filter = int(num_nonzero_indices * p_filter)\n",
    "\n",
    "            shuffled_indices = nonzero_indices[torch.randperm(num_nonzero_indices, device=flat_weights.device)]\n",
    "\n",
    "            indices_block = shuffled_indices[:num_block]\n",
    "            indices_reflect = shuffled_indices[num_block:num_block+num_reflect]\n",
    "            indices_filter = shuffled_indices[num_block+num_reflect:num_block+num_reflect+num_filter]\n",
    "\n",
    "            # do damage\n",
    "            # blockage: set weights to 0\n",
    "            if p_block != 0:\n",
    "                flat_weights[indices_block] = 0\n",
    "\n",
    "            # reflect: halve weights\n",
    "            if p_reflect != 0:\n",
    "                flat_weights[indices_reflect] *= 0.5\n",
    "\n",
    "            # filter: low pass filter (lusch et al)\n",
    "            if p_filter != 0:\n",
    "                weights_to_filter = flat_weights[indices_filter]            # get weights before transformation\n",
    "                signs = torch.sign(weights_to_filter)                       # get signs of weights\n",
    "                abs_weights_to_filter = weights_to_filter.abs()             # get high_weight, should be in the 95th percentile for all weights\n",
    "                high_weight = torch.quantile(flat_weights.abs(), 0.95)      # scale weights to mostly between -1 and 1\n",
    "                x = abs_weights_to_filter / high_weight\n",
    "                transformed_weights = -0.2744 * x**2 + 0.9094 * x - 0.0192\n",
    "                gaussian_noise = torch.randn_like(transformed_weights) * 0.05\n",
    "                transformed_weights += gaussian_noise\n",
    "                transformed_weights = transformed_weights * signs * high_weight # rescale\n",
    "                flat_weights[indices_filter] = transformed_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7354307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 10.7967\n",
      "Epoch 2 | Loss: 5.8020\n",
      "Epoch 3 | Loss: 3.9187\n",
      "Epoch 4 | Loss: 2.9592\n",
      "Epoch 5 | Loss: 2.6414\n",
      "Epoch 6 | Loss: 2.5206\n",
      "Epoch 7 | Loss: 2.3014\n",
      "Epoch 8 | Loss: 2.1733\n",
      "Epoch 9 | Loss: 2.0526\n",
      "Epoch 10 | Loss: 2.0793\n",
      "Epoch 11 | Loss: 1.9865\n",
      "Epoch 12 | Loss: 1.8658\n",
      "Epoch 13 | Loss: 1.8362\n",
      "Epoch 14 | Loss: 1.8057\n",
      "Epoch 15 | Loss: 1.7884\n",
      "Epoch 16 | Loss: 1.7921\n",
      "Epoch 17 | Loss: 1.7545\n",
      "Epoch 18 | Loss: 1.7719\n",
      "Epoch 19 | Loss: 1.7742\n",
      "Epoch 20 | Loss: 1.8082\n",
      "Epoch 21 | Loss: 1.7528\n",
      "Epoch 22 | Loss: 1.7542\n",
      "Epoch 23 | Loss: 1.7374\n",
      "Epoch 24 | Loss: 1.6930\n",
      "Epoch 25 | Loss: 1.7350\n",
      "Epoch 26 | Loss: 1.7194\n",
      "Epoch 27 | Loss: 1.6913\n",
      "Epoch 28 | Loss: 1.6560\n",
      "Epoch 29 | Loss: 1.6603\n",
      "Epoch 30 | Loss: 1.6906\n",
      "Epoch 31 | Loss: 1.6625\n",
      "Epoch 32 | Loss: 1.6420\n",
      "Epoch 33 | Loss: 1.6256\n",
      "Epoch 34 | Loss: 1.6889\n",
      "Epoch 35 | Loss: 1.6835\n",
      "Epoch 36 | Loss: 1.6425\n",
      "Epoch 37 | Loss: 1.6294\n",
      "Epoch 38 | Loss: 1.6111\n",
      "Epoch 39 | Loss: 1.6487\n",
      "Epoch 40 | Loss: 1.6299\n",
      "Epoch 41 | Loss: 1.6370\n",
      "Epoch 42 | Loss: 1.6555\n",
      "Epoch 43 | Loss: 1.6420\n",
      "Epoch 44 | Loss: 1.6306\n",
      "Epoch 45 | Loss: 1.6508\n",
      "Epoch 46 | Loss: 1.6515\n",
      "Epoch 47 | Loss: 1.6469\n",
      "Epoch 48 | Loss: 1.6214\n",
      "Epoch 49 | Loss: 1.6455\n",
      "Epoch 50 | Loss: 1.6550\n",
      "Epoch 51 | Loss: 1.6332\n",
      "Epoch 52 | Loss: 1.6485\n",
      "Epoch 53 | Loss: 1.6475\n",
      "Epoch 54 | Loss: 1.5864\n",
      "Epoch 55 | Loss: 1.5809\n",
      "Epoch 56 | Loss: 1.5925\n",
      "Epoch 57 | Loss: 1.6093\n",
      "Epoch 58 | Loss: 1.5997\n",
      "Epoch 59 | Loss: 1.6042\n",
      "Epoch 60 | Loss: 1.5911\n",
      "Epoch 61 | Loss: 1.6232\n",
      "Epoch 62 | Loss: 1.5791\n",
      "Epoch 63 | Loss: 1.5993\n",
      "Epoch 64 | Loss: 1.5843\n",
      "Epoch 65 | Loss: 1.5833\n",
      "Epoch 66 | Loss: 1.5842\n",
      "Epoch 67 | Loss: 1.6885\n",
      "Epoch 68 | Loss: 1.5739\n",
      "Epoch 69 | Loss: 1.5856\n",
      "Epoch 70 | Loss: 1.5602\n",
      "Epoch 71 | Loss: 1.5617\n",
      "Epoch 72 | Loss: 1.6187\n",
      "Epoch 73 | Loss: 1.5745\n",
      "Epoch 74 | Loss: 1.5558\n",
      "Epoch 75 | Loss: 1.5770\n",
      "Epoch 76 | Loss: 1.5513\n",
      "Epoch 77 | Loss: 1.5520\n",
      "Epoch 78 | Loss: 1.5410\n",
      "Epoch 79 | Loss: 1.5576\n",
      "Epoch 80 | Loss: 1.5274\n",
      "Epoch 81 | Loss: 1.5737\n",
      "Epoch 82 | Loss: 1.5120\n",
      "Epoch 83 | Loss: 1.5496\n",
      "Epoch 84 | Loss: 1.5221\n",
      "Epoch 85 | Loss: 1.5443\n",
      "Epoch 86 | Loss: 1.5333\n",
      "Epoch 87 | Loss: 1.5796\n",
      "Epoch 88 | Loss: 1.5652\n",
      "Epoch 89 | Loss: 1.6020\n",
      "Epoch 90 | Loss: 1.5136\n",
      "Epoch 91 | Loss: 1.5091\n",
      "Epoch 92 | Loss: 1.5098\n",
      "Epoch 93 | Loss: 1.4967\n",
      "Epoch 94 | Loss: 1.5152\n",
      "Epoch 95 | Loss: 1.5196\n",
      "Epoch 96 | Loss: 1.4809\n",
      "Epoch 97 | Loss: 1.5086\n",
      "Epoch 98 | Loss: 1.4859\n",
      "Epoch 99 | Loss: 1.5071\n",
      "Epoch 100 | Loss: 1.5372\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DigitToStrokeLSTM().to(device)\n",
    "\n",
    "# # damage weights to simulate energy constraint and lesioning\n",
    "# damage_smallest(model, 0.0)\n",
    "# damage_fas(model, 0.0, 0.0, 0.0)\n",
    "\n",
    "dx_dy_loss_fn = nn.MSELoss()\n",
    "eos_eod_loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (dig, input_seq, output_seq) in loader:\n",
    "        # stroke_seq: [batch, seq_len, 4]\n",
    "        input_seq = input_seq.to(device)\n",
    "        target_seq = output_seq.to(device)\n",
    "        dig = dig.to(device)\n",
    "\n",
    "        pred_seq, hidden = model(input_seq, onehot_digit = dig)  # [batch, seq_len-1, 4]\n",
    "\n",
    "        # Separate predictions\n",
    "        pred_dxdy = pred_seq[..., :2]         # [batch, seq_len-1, 2]\n",
    "        pred_eos_eod = pred_seq[..., 2:]      # [batch, seq_len-1, 2]\n",
    "\n",
    "        # Separate targets\n",
    "        target_dxdy = target_seq[..., :2]\n",
    "        target_eos_eod = target_seq[..., 2:]\n",
    "\n",
    "        # Compute losses\n",
    "        loss_dxdy = dx_dy_loss_fn(pred_dxdy, target_dxdy)\n",
    "        loss_eos_eod = eos_eod_loss_fn(pred_eos_eod, target_eos_eod)\n",
    "\n",
    "        loss = loss_dxdy + loss_eos_eod\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0d776b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(number):\n",
    "    model.eval()\n",
    "    \n",
    "    temp_onehot = np.zeros(10)\n",
    "    temp_onehot[number] = 1\n",
    "    temp_onehot = torch.tensor(temp_onehot, dtype=torch.float32).to(device)\n",
    "    \n",
    "    initial_input = torch.tensor([0, 0, 0, 0], dtype=torch.float32).to(device).unsqueeze(0).unsqueeze(1)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    output, hidden = model(initial_input, onehot_digit=temp_onehot)\n",
    "    output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "\n",
    "    outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "\n",
    "    for i in range(max_length-1):\n",
    "        output, hidden = model(output, hidden=hidden)\n",
    "        output[..., 2:] = (torch.sigmoid(output[..., -1, 2:]) > 0.5).float()\n",
    "        outputs.append(output[:, -1, :].detach().cpu().numpy()[0])\n",
    "        \n",
    "        # print(outputs[-1])\n",
    "        if output[:, -1, 3] == 1:\n",
    "            # print(\"HI\")\n",
    "            break\n",
    "    \n",
    "    draw_stroke_sequence(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e548538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1ac7a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save model if good\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save model if good\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e579b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitToStrokeLSTM(\n",
       "  (embedding): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (lstm): LSTM(4, 256, num_layers=2, batch_first=True)\n",
       "  (output_head): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DigitToStrokeLSTM().to(device) # create a new instance\n",
    "model.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
    "model.eval()  # set to evaluation mode if you're doing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ec9780",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     13\u001b[0m output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m:]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mmax_length\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     18\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m model(output, hidden\u001b[38;5;241m=\u001b[39mhidden)\n\u001b[0;32m     19\u001b[0m     output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m:]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_length' is not defined"
     ]
    }
   ],
   "source": [
    "generate_text(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shit: 0, 5, 6, 8, 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
