{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea2f62c",
   "metadata": {},
   "source": [
    "AUTOREGRESSIVE RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1143c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import one_hot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create vocabulary\n",
    "sequences = [\"hello*\", \"help*\", \"held*\", \"hero*\"]\n",
    "\n",
    "text = \"\".join(sequences)\n",
    "chars = sorted(list(set(text)))\n",
    "char2idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx2char = {idx: ch for ch, idx in char2idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# Convert to index tensors\n",
    "def encode_sequence(seq):\n",
    "    return torch.tensor([char2idx[ch] for ch in seq], dtype=torch.long)\n",
    "\n",
    "encoded_seqs = [encode_sequence(seq) for seq in sequences]\n",
    "\n",
    "# Pad sequences to equal length\n",
    "padded_seqs = pad_sequence(encoded_seqs, batch_first=True, padding_value=char2idx['*'])\n",
    "\n",
    "# Inputs: everything except last character\n",
    "# Targets: everything except first character\n",
    "inputs = padded_seqs[:, :-1]\n",
    "targets = padded_seqs[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "976386c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abaf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Hidden state and cell state for LSTM\n",
    "        h_0 = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        return (h_0, c_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af44179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.4937\n",
      "Epoch [20/100], Loss: 1.1803\n",
      "Epoch [30/100], Loss: 0.8045\n",
      "Epoch [40/100], Loss: 0.5258\n",
      "Epoch [50/100], Loss: 0.3842\n",
      "Epoch [60/100], Loss: 0.3205\n",
      "Epoch [70/100], Loss: 0.2973\n",
      "Epoch [80/100], Loss: 0.2890\n",
      "Epoch [90/100], Loss: 0.2854\n",
      "Epoch [100/100], Loss: 0.2836\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the whole batch\n",
    "inputs_onehot = one_hot(inputs, num_classes=vocab_size).float().to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "model = CharLSTM(vocab_size, hidden_size=32, output_size=vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "    \n",
    "    output, hidden = model(inputs_onehot, hidden)\n",
    "    loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf25223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 4, 4, 5])\n",
      "hello*\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff00adac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello*', 'help*']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0:2]\n",
    "# sequences[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a492c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs_onehot[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bd6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8710e-04, 2.2229e-04, 9.9574e-01, 2.2217e-04, 1.2073e-03, 2.9980e-05,\n",
      "        1.6896e-04, 2.1258e-03])\n",
      "tensor([3.2202e-05, 1.0839e-03, 7.8603e-04, 1.1017e-05, 7.4959e-01, 2.8671e-05,\n",
      "        1.1256e-03, 2.4735e-01])\n",
      "tensor([1.7208e-04, 3.3177e-01, 1.5226e-05, 2.5069e-05, 3.3064e-01, 7.5784e-03,\n",
      "        3.2781e-01, 1.9950e-03])\n",
      "tensor([1.5544e-02, 2.0982e-03, 2.4264e-06, 1.6779e-05, 1.0912e-03, 9.7899e-01,\n",
      "        2.2333e-03, 2.6440e-05])\n",
      "tensor([9.9909e-01, 9.7474e-06, 8.7536e-06, 9.0646e-06, 2.1478e-05, 8.5166e-04,\n",
      "        8.9895e-06, 1.7287e-06])\n",
      "Generated: hello\n"
     ]
    }
   ],
   "source": [
    "def generate_text(start_char='h', max_len=20, stop_char='*'):\n",
    "    model.eval()\n",
    "    input_char_idx = torch.tensor([[char2idx[start_char]]])\n",
    "    input_onehot = one_hot(input_char_idx, num_classes=vocab_size).float().to(device)\n",
    "    hidden = model.init_hidden(batch_size=1)\n",
    "    generated = start_char\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        output, hidden = model(input_onehot, hidden)\n",
    "        probs = torch.softmax(output[0, -1], dim=0).detach().cpu()\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        next_char = idx2char[next_idx]\n",
    "        if next_char == stop_char:\n",
    "            break\n",
    "        generated += next_char\n",
    "\n",
    "        input_onehot = one_hot(torch.tensor([[next_idx]]), num_classes=vocab_size).float().to(device)\n",
    "\n",
    "    return generated\n",
    "\n",
    "print(\"Generated:\", generate_text('h'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e2716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e9bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
